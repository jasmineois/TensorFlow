{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "予測モデルを作成する関数\n",
    "@param images_placeholder - 画像のplaceholder\n",
    "@param keep_prob - dropout率のplace_holder\n",
    "@return y_conv - 各クラスの確率(のようなもの)\n",
    "\"\"\"\n",
    "def inference(images_placeholder, keep_prob):\n",
    "\n",
    "    # 重みを標準偏差0.1の正規分布で初期化\n",
    "    def weight_variable(shape):\n",
    "      initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "      return tf.Variable(initial)\n",
    "\n",
    "    # バイアスを標準偏差0.1の正規分布で初期化\n",
    "    def bias_variable(shape):\n",
    "      initial = tf.constant(0.1, shape=shape)\n",
    "      return tf.Variable(initial)\n",
    "\n",
    "    # 畳み込み層の作成\n",
    "    def conv2d(x, W):\n",
    "      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    # プーリング層の作成\n",
    "    def max_pool_2x2(x):\n",
    "      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # 入力を28x28x3に変形\n",
    "    x_image = tf.reshape(images_placeholder, [-1, 28, 28, 3])\n",
    "\n",
    "    # 畳み込み層1の作成\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        W_conv1 = weight_variable([5, 5, 3, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "    # プーリング層1の作成\n",
    "    with tf.name_scope('pool1') as scope:\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "    # 畳み込み層2の作成\n",
    "    with tf.name_scope('conv2') as scope:\n",
    "        W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "    # プーリング層2の作成\n",
    "    with tf.name_scope('pool2') as scope:\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "    # 全結合層1の作成\n",
    "    with tf.name_scope('fc1') as scope:\n",
    "        W_fc1 = weight_variable([7*7*64, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "        # dropoutの設定\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "    # 全結合層2の作成\n",
    "    with tf.name_scope('fc2') as scope:\n",
    "        W_fc2 = weight_variable([1024, NUM_CLASSES])\n",
    "        b_fc2 = bias_variable([NUM_CLASSES])\n",
    "\n",
    "    # ソフトマックス関数による正規化\n",
    "    with tf.name_scope('softmax') as scope:\n",
    "        y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "    # 各ラベルの確率のようなものを返す\n",
    "    return y_conv\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "lossを計算する関数\n",
    "@param logits - ロジットのtensor, float - [batch_size, NUM_CLASSES]\n",
    "@param labels -  ラベルのtensor, int32 - [batch_size, NUM_CLASSES]\n",
    "@return cross_entropy: 交差エントロピーのtensor, float\n",
    "\"\"\"\n",
    "def loss(logits, labels):\n",
    "    # 交差エントロピーの計算\n",
    "    cross_entropy = -tf.reduce_sum(labels*tf.log(logits))\n",
    "    # TensorBoardで表示するよう指定\n",
    "    tf.scalar_summary(\"cross_entropy\", cross_entropy)\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "訓練のOpを定義する関数\n",
    "@param loss - 損失のtensor, loss()の結果\n",
    "@param learning_rate - 学習係数\n",
    "@return train_step - 訓練のOp\n",
    "\"\"\"\n",
    "def training(loss, learning_rate):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    return train_step\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "正解率(accuracy)を計算する関数\n",
    "@param logits - inference()の結果\n",
    "@param labels - ラベルのtensor, int32 - [batch_size, NUM_CLASSES]\n",
    "@return accuracy - 正解率(float)\n",
    "\"\"\"\n",
    "def accuracy(logits, labels):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    tf.scalar_summary(\"accuracy\", accuracy)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "image/cut/ayana4.jpg\n",
      "image/cut/ayana5.jpg\n",
      "image/cut/ayana6.jpg\n",
      "image/cut/hana4.jpg\n",
      "image/cut/hana5.jpg\n",
      "image/cut/hana6.jpg\n",
      "image/cut/hana7.jpg\n",
      "image/cut/hana8.jpg\n",
      "image/cut/inori4.jpg\n",
      "image/cut/inori5.jpg\n",
      "------------------------------------\n",
      "image/cut/ayana0.jpg\n",
      "image/cut/ayana1.jpg\n",
      "image/cut/ayana2.jpg\n",
      "image/cut/ayana3.jpg\n",
      "image/cut/hana0.jpg\n",
      "image/cut/hana1.jpg\n",
      "image/cut/hana2.jpg\n",
      "image/cut/hana3.jpg\n",
      "image/cut/inori0.jpg\n",
      "image/cut/inori1.jpg\n",
      "image/cut/inori2.jpg\n",
      "image/cut/inori3.jpg\n",
      "------------------------------------\n",
      "WARNING:tensorflow:From <ipython-input-28-00643faa19a1>:82 in loss.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-28-00643faa19a1>:106 in accuracy.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:From <ipython-input-41-278bb23e7f45>:75 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From <ipython-input-41-278bb23e7f45>:78 in <module>.: merge_all_summaries (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge_all.\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\logging_ops.py:264 in merge_all_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.merge.\n",
      "WARNING:tensorflow:From <ipython-input-41-278bb23e7f45>:79 in <module>.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
      "step 0, training accuracy 0.3\n",
      "step 1, training accuracy 0.3\n",
      "step 2, training accuracy 0.3\n",
      "step 3, training accuracy 0.5\n",
      "step 4, training accuracy 0.6\n",
      "step 5, training accuracy 0.5\n",
      "step 6, training accuracy 0.5\n",
      "step 7, training accuracy 0.5\n",
      "step 8, training accuracy 0.5\n",
      "step 9, training accuracy 0.5\n",
      "step 10, training accuracy 0.5\n",
      "step 11, training accuracy 0.5\n",
      "step 12, training accuracy 0.6\n",
      "step 13, training accuracy 0.7\n",
      "step 14, training accuracy 0.7\n",
      "step 15, training accuracy 0.7\n",
      "step 16, training accuracy 0.8\n",
      "step 17, training accuracy 0.8\n",
      "step 18, training accuracy 0.8\n",
      "step 19, training accuracy 0.9\n",
      "step 20, training accuracy 1\n",
      "step 21, training accuracy 0.9\n",
      "step 22, training accuracy 0.8\n",
      "step 23, training accuracy 0.8\n",
      "step 24, training accuracy 0.9\n",
      "step 25, training accuracy 0.9\n",
      "step 26, training accuracy 0.8\n",
      "step 27, training accuracy 0.7\n",
      "step 28, training accuracy 0.8\n",
      "step 29, training accuracy 0.8\n",
      "step 30, training accuracy 0.8\n",
      "step 31, training accuracy 0.8\n",
      "step 32, training accuracy 0.8\n",
      "step 33, training accuracy 0.8\n",
      "step 34, training accuracy 0.9\n",
      "step 35, training accuracy 0.9\n",
      "step 36, training accuracy 0.9\n",
      "step 37, training accuracy 0.9\n",
      "step 38, training accuracy 0.9\n",
      "step 39, training accuracy 0.9\n",
      "step 40, training accuracy 0.9\n",
      "step 41, training accuracy 0.9\n",
      "step 42, training accuracy 0.9\n",
      "step 43, training accuracy 1\n",
      "step 44, training accuracy 1\n",
      "step 45, training accuracy 1\n",
      "step 46, training accuracy 1\n",
      "step 47, training accuracy 1\n",
      "step 48, training accuracy 0.9\n",
      "step 49, training accuracy 0.9\n",
      "step 50, training accuracy 0.9\n",
      "step 51, training accuracy 0.9\n",
      "step 52, training accuracy 0.9\n",
      "step 53, training accuracy 0.9\n",
      "step 54, training accuracy 0.9\n",
      "step 55, training accuracy 0.9\n",
      "step 56, training accuracy 0.9\n",
      "step 57, training accuracy 1\n",
      "step 58, training accuracy 1\n",
      "step 59, training accuracy 1\n",
      "step 60, training accuracy 1\n",
      "step 61, training accuracy 1\n",
      "step 62, training accuracy 1\n",
      "step 63, training accuracy 1\n",
      "step 64, training accuracy 1\n",
      "step 65, training accuracy 1\n",
      "step 66, training accuracy 1\n",
      "step 67, training accuracy 1\n",
      "step 68, training accuracy 1\n",
      "step 69, training accuracy 1\n",
      "step 70, training accuracy 1\n",
      "step 71, training accuracy 1\n",
      "step 72, training accuracy 1\n",
      "step 73, training accuracy 1\n",
      "step 74, training accuracy 1\n",
      "step 75, training accuracy 1\n",
      "step 76, training accuracy 1\n",
      "step 77, training accuracy 1\n",
      "step 78, training accuracy 1\n",
      "step 79, training accuracy 1\n",
      "step 80, training accuracy 1\n",
      "step 81, training accuracy 1\n",
      "step 82, training accuracy 1\n",
      "step 83, training accuracy 1\n",
      "step 84, training accuracy 1\n",
      "step 85, training accuracy 1\n",
      "step 86, training accuracy 1\n",
      "step 87, training accuracy 1\n",
      "step 88, training accuracy 1\n",
      "step 89, training accuracy 1\n",
      "step 90, training accuracy 1\n",
      "step 91, training accuracy 1\n",
      "step 92, training accuracy 1\n",
      "step 93, training accuracy 1\n",
      "step 94, training accuracy 1\n",
      "step 95, training accuracy 1\n",
      "step 96, training accuracy 1\n",
      "step 97, training accuracy 1\n",
      "step 98, training accuracy 1\n",
      "step 99, training accuracy 1\n",
      "step 100, training accuracy 1\n",
      "step 101, training accuracy 1\n",
      "step 102, training accuracy 1\n",
      "step 103, training accuracy 1\n",
      "step 104, training accuracy 1\n",
      "step 105, training accuracy 1\n",
      "step 106, training accuracy 1\n",
      "step 107, training accuracy 1\n",
      "step 108, training accuracy 1\n",
      "step 109, training accuracy 1\n",
      "step 110, training accuracy 1\n",
      "step 111, training accuracy 1\n",
      "step 112, training accuracy 1\n",
      "step 113, training accuracy 1\n",
      "step 114, training accuracy 1\n",
      "step 115, training accuracy 1\n",
      "step 116, training accuracy 1\n",
      "step 117, training accuracy 1\n",
      "step 118, training accuracy 1\n",
      "step 119, training accuracy 1\n",
      "step 120, training accuracy 1\n",
      "step 121, training accuracy 1\n",
      "step 122, training accuracy 1\n",
      "step 123, training accuracy 1\n",
      "step 124, training accuracy 1\n",
      "step 125, training accuracy 1\n",
      "step 126, training accuracy 1\n",
      "step 127, training accuracy 1\n",
      "step 128, training accuracy 1\n",
      "step 129, training accuracy 1\n",
      "step 130, training accuracy 1\n",
      "step 131, training accuracy 1\n",
      "step 132, training accuracy 1\n",
      "step 133, training accuracy 1\n",
      "step 134, training accuracy 1\n",
      "step 135, training accuracy 1\n",
      "step 136, training accuracy 1\n",
      "step 137, training accuracy 1\n",
      "step 138, training accuracy 1\n",
      "step 139, training accuracy 1\n",
      "step 140, training accuracy 1\n",
      "step 141, training accuracy 1\n",
      "step 142, training accuracy 1\n",
      "step 143, training accuracy 1\n",
      "step 144, training accuracy 1\n",
      "step 145, training accuracy 1\n",
      "step 146, training accuracy 1\n",
      "step 147, training accuracy 1\n",
      "step 148, training accuracy 1\n",
      "step 149, training accuracy 1\n",
      "step 150, training accuracy 1\n",
      "step 151, training accuracy 1\n",
      "step 152, training accuracy 1\n",
      "step 153, training accuracy 1\n",
      "step 154, training accuracy 1\n",
      "step 155, training accuracy 1\n",
      "step 156, training accuracy 1\n",
      "step 157, training accuracy 1\n",
      "step 158, training accuracy 1\n",
      "step 159, training accuracy 1\n",
      "step 160, training accuracy 1\n",
      "step 161, training accuracy 1\n",
      "step 162, training accuracy 1\n",
      "step 163, training accuracy 1\n",
      "step 164, training accuracy 1\n",
      "step 165, training accuracy 1\n",
      "step 166, training accuracy 1\n",
      "step 167, training accuracy 1\n",
      "step 168, training accuracy 1\n",
      "step 169, training accuracy 1\n",
      "step 170, training accuracy 1\n",
      "step 171, training accuracy 1\n",
      "step 172, training accuracy 1\n",
      "step 173, training accuracy 1\n",
      "step 174, training accuracy 1\n",
      "step 175, training accuracy 1\n",
      "step 176, training accuracy 1\n",
      "step 177, training accuracy 1\n",
      "step 178, training accuracy 1\n",
      "step 179, training accuracy 1\n",
      "step 180, training accuracy 1\n",
      "step 181, training accuracy 1\n",
      "step 182, training accuracy 1\n",
      "step 183, training accuracy 1\n",
      "step 184, training accuracy 1\n",
      "step 185, training accuracy 1\n",
      "step 186, training accuracy 1\n",
      "step 187, training accuracy 1\n",
      "step 188, training accuracy 1\n",
      "step 189, training accuracy 1\n",
      "step 190, training accuracy 1\n",
      "step 191, training accuracy 1\n",
      "step 192, training accuracy 1\n",
      "step 193, training accuracy 1\n",
      "step 194, training accuracy 1\n",
      "step 195, training accuracy 1\n",
      "step 196, training accuracy 1\n",
      "step 197, training accuracy 1\n",
      "step 198, training accuracy 1\n",
      "step 199, training accuracy 1\n",
      "step 200, training accuracy 1\n",
      "step 201, training accuracy 1\n",
      "step 202, training accuracy 1\n",
      "step 203, training accuracy 1\n",
      "step 204, training accuracy 1\n",
      "step 205, training accuracy 1\n",
      "step 206, training accuracy 1\n",
      "step 207, training accuracy 1\n",
      "step 208, training accuracy 1\n",
      "step 209, training accuracy 1\n",
      "step 210, training accuracy 1\n",
      "step 211, training accuracy 1\n",
      "step 212, training accuracy 1\n",
      "step 213, training accuracy 1\n",
      "step 214, training accuracy 1\n",
      "step 215, training accuracy 1\n",
      "step 216, training accuracy 1\n",
      "step 217, training accuracy 1\n",
      "step 218, training accuracy 1\n",
      "step 219, training accuracy 1\n",
      "step 220, training accuracy 1\n",
      "step 221, training accuracy 1\n",
      "step 222, training accuracy 1\n",
      "step 223, training accuracy 1\n",
      "step 224, training accuracy 1\n",
      "step 225, training accuracy 1\n",
      "step 226, training accuracy 1\n",
      "step 227, training accuracy 1\n",
      "step 228, training accuracy 1\n",
      "step 229, training accuracy 1\n",
      "step 230, training accuracy 1\n",
      "step 231, training accuracy 1\n",
      "step 232, training accuracy 1\n",
      "step 233, training accuracy 1\n",
      "step 234, training accuracy 1\n",
      "step 235, training accuracy 1\n",
      "step 236, training accuracy 1\n",
      "step 237, training accuracy 1\n",
      "step 238, training accuracy 1\n",
      "step 239, training accuracy 1\n",
      "step 240, training accuracy 1\n",
      "step 241, training accuracy 1\n",
      "step 242, training accuracy 1\n",
      "step 243, training accuracy 1\n",
      "step 244, training accuracy 1\n",
      "step 245, training accuracy 1\n",
      "step 246, training accuracy 1\n",
      "step 247, training accuracy 1\n",
      "step 248, training accuracy 1\n",
      "step 249, training accuracy 1\n",
      "step 250, training accuracy 1\n",
      "step 251, training accuracy 1\n",
      "step 252, training accuracy 1\n",
      "step 253, training accuracy 1\n",
      "step 254, training accuracy 1\n",
      "step 255, training accuracy 1\n",
      "step 256, training accuracy 1\n",
      "step 257, training accuracy 1\n",
      "step 258, training accuracy 1\n",
      "step 259, training accuracy 1\n",
      "step 260, training accuracy 1\n",
      "step 261, training accuracy 1\n",
      "step 262, training accuracy 1\n",
      "step 263, training accuracy 1\n",
      "step 264, training accuracy 1\n",
      "step 265, training accuracy 1\n",
      "step 266, training accuracy 1\n",
      "step 267, training accuracy 1\n",
      "step 268, training accuracy 1\n",
      "step 269, training accuracy 1\n",
      "step 270, training accuracy 1\n",
      "step 271, training accuracy 1\n",
      "step 272, training accuracy 1\n",
      "step 273, training accuracy 1\n",
      "step 274, training accuracy 1\n",
      "step 275, training accuracy 1\n",
      "step 276, training accuracy 1\n",
      "step 277, training accuracy 1\n",
      "step 278, training accuracy 1\n",
      "step 279, training accuracy 1\n",
      "step 280, training accuracy 1\n",
      "step 281, training accuracy 1\n",
      "step 282, training accuracy 1\n",
      "step 283, training accuracy 1\n",
      "step 284, training accuracy 1\n",
      "step 285, training accuracy 1\n",
      "step 286, training accuracy 1\n",
      "step 287, training accuracy 1\n",
      "step 288, training accuracy 1\n",
      "step 289, training accuracy 1\n",
      "step 290, training accuracy 1\n",
      "step 291, training accuracy 1\n",
      "step 292, training accuracy 1\n",
      "step 293, training accuracy 1\n",
      "step 294, training accuracy 1\n",
      "step 295, training accuracy 1\n",
      "step 296, training accuracy 1\n",
      "step 297, training accuracy 1\n",
      "step 298, training accuracy 1\n",
      "step 299, training accuracy 1\n",
      "test accuracy 0.666667\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    print('------------------------------------')\n",
    "    # ファイルを開く\n",
    "    f = open('data/train.txt', 'r')\n",
    "    # データを入れる配列\n",
    "    train_image = []\n",
    "    train_label = []\n",
    "    for line in f:\n",
    "        # 改行を除いてスペース区切りにする\n",
    "        line = line.rstrip()\n",
    "        l = line.split()\n",
    "        # パス\n",
    "        p = l[0]\n",
    "        print(p)\n",
    "        # データを読み込んで28x28に縮小\n",
    "        img = cv2.imread(p)\n",
    "        img = cv2.resize(img, (28, 28))\n",
    "        # 一列にした後、0-1のfloat値にする\n",
    "        train_image.append(img.flatten().astype(np.float32)/255.0)\n",
    "        # ラベルを1-of-k方式で用意する\n",
    "        tmp = np.zeros(NUM_CLASSES)\n",
    "        tmp[int(l[1])] = 1\n",
    "        train_label.append(tmp)\n",
    "    # numpy形式に変換\n",
    "    train_image = np.asarray(train_image)\n",
    "    train_label = np.asarray(train_label)\n",
    "    f.close()\n",
    "    # print(train_image)\n",
    "    # print(train_label)\n",
    "    \n",
    "    print('------------------------------------')\n",
    "    f = open('data/test.txt', 'r')\n",
    "    test_image = []\n",
    "    test_label = []\n",
    "    for line in f:\n",
    "        line = line.rstrip()\n",
    "        l = line.split()\n",
    "        p = l[0]\n",
    "        print(p)\n",
    "        img = cv2.imread(p)\n",
    "        img = cv2.resize(img, (28, 28))\n",
    "        test_image.append(img.flatten().astype(np.float32)/255.0)\n",
    "        tmp = np.zeros(NUM_CLASSES)\n",
    "        tmp[int(l[1])] = 1\n",
    "        test_label.append(tmp)\n",
    "    test_image = np.asarray(test_image)\n",
    "    test_label = np.asarray(test_label)\n",
    "    f.close()\n",
    "\n",
    "    print('------------------------------------')\n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        images_placeholder = tf.placeholder(\"float\", shape=(None, 28*28*3))\n",
    "        labels_placeholder = tf.placeholder(\"float\", shape=(None, NUM_CLASSES))\n",
    "        keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "        # inference → loss → training\n",
    "        logits = inference(images_placeholder, keep_prob)\n",
    "        loss_value = loss(logits, labels_placeholder)\n",
    "        train_op = training(loss_value, 1e-4)\n",
    "        acc = accuracy(logits, labels_placeholder)\n",
    "\n",
    "        # Session\n",
    "        saver = tf.train.Saver()\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "\n",
    "        # TensorBoardで表示する値の設定\n",
    "        summary_op = tf.merge_all_summaries()\n",
    "        summary_writer = tf.train.SummaryWriter('image/train/', sess.graph_def)\n",
    "        \n",
    "        # 訓練の実行\n",
    "        for step in range(300):\n",
    "            for i in range(1):\n",
    "                # batch_size分の画像に対して訓練の実行\n",
    "                batch = 10*i\n",
    "                # feed_dictでplaceholderに入れるデータを指定する\n",
    "                sess.run(train_op, feed_dict={\n",
    "                  images_placeholder: train_image[batch:batch+10],\n",
    "                  labels_placeholder: train_label[batch:batch+10],\n",
    "                  keep_prob: 0.5})\n",
    "\n",
    "            # 1 step終わるたびに精度を計算する\n",
    "            train_accuracy = sess.run(acc, feed_dict={\n",
    "                images_placeholder: train_image,\n",
    "                labels_placeholder: train_label,\n",
    "                keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(step, train_accuracy))\n",
    "\n",
    "            # 1 step終わるたびにTensorBoardに表示する値を追加する\n",
    "            summary_str = sess.run(summary_op, feed_dict={\n",
    "                images_placeholder: train_image,\n",
    "                labels_placeholder: train_label,\n",
    "                keep_prob: 1.0})\n",
    "            summary_writer.add_summary(summary_str, step)\n",
    "        \n",
    "    # 訓練が終了したらテストデータに対する精度を表示\n",
    "    print(\"test accuracy %g\"%sess.run(acc, feed_dict={\n",
    "        images_placeholder: test_image,\n",
    "        labels_placeholder: test_label,\n",
    "        keep_prob: 1.0}))\n",
    "\n",
    "    # 最終的なモデルを保存\n",
    "    # save_path = saver.save(sess, \"model.ckpt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
